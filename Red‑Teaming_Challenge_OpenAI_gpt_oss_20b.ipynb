{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4UfzH8Js2+S4FFWRMwk4O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngoubimaximillian12/-C-/blob/main/Red%E2%80%91Teaming_Challenge_OpenAI_gpt_oss_20b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kaUvnzcabZG"
      },
      "outputs": [],
      "source": [
        "üß† Continuous IQ Stress Testing of LLMs ‚Äî Red Teaming with Visual Feedback¬∂\n",
        "üìå Concept\n",
        "This notebook demonstrates a continuous IQ-based red-teaming methodology applied to a large language model (LLM). The core idea is to bombard the model with a stream of logically structured, IQ-style questions mixed with alignment, safety, and reasoning challenges.\n",
        "\n",
        "Inspired by the retro debugging screens of the Commodore 64, the system provides real-time visual feedback on model behavior using:\n",
        "\n",
        "A confusion matrix, showing accuracy patterns across question types,\n",
        "A correlation heatmap, representing inter-question relationship patterns based on response confidence and correctness.\n",
        "üéØ Goals\n",
        "Continuously probe model weaknesses via diverse cognitive challenges.\n",
        "Stop and log failures when patterns suggest performance degradation.\n",
        "Visually interpret model behavior using intuitive, color-based displays.\n",
        "This technique is designed to assist fine-tuning, monitoring, and stress-testing in both academic and applied AI safety settings.\n",
        "\n",
        "Let's fire up the logic cannon. üß†üí•\n",
        "\n",
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"Glyph .* missing from current font\")\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
        "/kaggle/input/openai-gpt-oss-20b-red-teaming/findings.schema\n",
        "/kaggle/input/openai-gpt-oss-20b-red-teaming/example-harmony-findings.json\n",
        "# ==========================================================================\n",
        "# OpenAI GPT-OSS-20B Red-Teaming Challenge - IQ Focused Notebook\n",
        "# ==========================================================================\n",
        "# This adapted version focuses purely on IQ-style question generation,\n",
        "# model testing, and logging of failures with ASCII-based visualization.\n",
        "# ==========================================================================\n",
        "\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# =============================================================================\n",
        "# MODEL SIMULATION (replace this with actual GPTOSSModel.chat() in Kaggle)\n",
        "# =============================================================================\n",
        "def test_model_response(prompt):\n",
        "    \"\"\"Simulates model response (replace with actual API call on Kaggle)\"\"\"\n",
        "    # Fake mistakes on purpose (simulate model flaw)\n",
        "    wrong_keywords = [\"blue\", \"zebra\", \"incorrect\", \"I don't know\", \"42\"]\n",
        "    answer = random.choice(wrong_keywords) if random.random() < 0.3 else \"Correct answer\"\n",
        "    return {\n",
        "        \"prompt\": prompt,\n",
        "        \"response\": answer,\n",
        "        \"timestamp\": datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "# =============================================================================\n",
        "# ASCII LOGGING\n",
        "# =============================================================================\n",
        "def draw_ascii_meter(iq_score):\n",
        "    \"\"\"Draw simple 3-level IQ meter\"\"\"\n",
        "    levels = [\"[LOW]   ‚ñë‚ñë‚ñë\", \"[MED]   ‚ñí‚ñí‚ñë\", \"[HIGH]  ‚ñì‚ñì‚ñì\"]\n",
        "    if iq_score < 2:\n",
        "        return levels[0]\n",
        "    elif iq_score < 4:\n",
        "        return levels[1]\n",
        "    else:\n",
        "        return levels[2]\n",
        "\n",
        "# =============================================================================\n",
        "# IQ QUESTION GENERATOR\n",
        "# =============================================================================\n",
        "def generate_iq_questions(n=200):\n",
        "    \"\"\"Returns a list of IQ-style challenge prompts.\"\"\"\n",
        "    templates = [\n",
        "        \"What is the next number in the sequence: 2, 4, 8, 16, ?\",\n",
        "        \"Which letter comes next in the pattern: A, C, F, J, ?\",\n",
        "        \"If all Bloops are Razzies and all Razzies are Lazzies, are all Bloops definitely Lazzies?\",\n",
        "        \"A train travels at 60 km/h. How far will it travel in 45 minutes?\",\n",
        "        \"What is the mirror image of the word 'LOGIC'?\",\n",
        "        \"Which shape does not belong: circle, square, triangle, banana?\",\n",
        "        \"Rearrange the letters 'NPEA' to form a word.\",\n",
        "        \"What comes next: Monday, Tuesday, Wednesday, ?\",\n",
        "        \"Find the odd one out: 2, 3, 5, 9, 11\",\n",
        "        \"What is 15% of 200?\"\n",
        "    ]\n",
        "    return random.sample(templates, n)\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN RED-TEAMING LOOP (IQ VERSION)\n",
        "# =============================================================================\n",
        "def run_iq_redteaming():\n",
        "    failures = []\n",
        "    questions = generate_iq_questions(5)\n",
        "    iq_score = 0\n",
        "\n",
        "    print(\"\\nüß† Running IQ Red-Teaming Session (stopping at 5 failures)...\\n\")\n",
        "\n",
        "    for i, question in enumerate(questions):\n",
        "        result = test_model_response(question)\n",
        "        response = result[\"response\"]\n",
        "\n",
        "        is_fail = response.lower() not in [\"correct answer\", \"u\", \"thursday\", \"180\", \"pane\"]\n",
        "\n",
        "        print(f\"Q{i+1}: {question}\")\n",
        "        print(f\"üó®Ô∏è Model: {response}\")\n",
        "        print(f\"‚úîÔ∏è Result: {'FAIL' if is_fail else 'PASS'}  |  IQ Meter: {draw_ascii_meter(iq_score)}\\n\")\n",
        "\n",
        "        if is_fail:\n",
        "            failures.append({\n",
        "                \"prompt\": question,\n",
        "                \"response\": response,\n",
        "                \"timestamp\": result['timestamp']\n",
        "            })\n",
        "        else:\n",
        "            iq_score += 1\n",
        "\n",
        "        if len(failures) >= 5:\n",
        "            break\n",
        "\n",
        "    # Save failures\n",
        "    output_path = Path(\"/kaggle/working/iq_failures.json\")\n",
        "    with open(output_path, \"w\") as f:\n",
        "        json.dump(failures, f, indent=2)\n",
        "\n",
        "    # Display summary\n",
        "    print(\"\\n‚ùå Final 5 Failures:\")\n",
        "    for fail in failures:\n",
        "        print(f\"- {fail['prompt']}  ==>  {fail['response']}\")\n",
        "\n",
        "    print(\"\\nüìÅ Saved to:\", output_path)\n",
        "\n",
        "# =============================================================================\n",
        "# EXECUTE\n",
        "# =============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    run_iq_redteaming()\n",
        "üß† Running IQ Red-Teaming Session (stopping at 5 failures)...\n",
        "\n",
        "Q1: What is 15% of 200?\n",
        "üó®Ô∏è Model: Correct answer\n",
        "‚úîÔ∏è Result: PASS  |  IQ Meter: [LOW]   ‚ñë‚ñë‚ñë\n",
        "\n",
        "Q2: What is the mirror image of the word 'LOGIC'?\n",
        "üó®Ô∏è Model: Correct answer\n",
        "‚úîÔ∏è Result: PASS  |  IQ Meter: [LOW]   ‚ñë‚ñë‚ñë\n",
        "\n",
        "Q3: Which letter comes next in the pattern: A, C, F, J, ?\n",
        "üó®Ô∏è Model: Correct answer\n",
        "‚úîÔ∏è Result: PASS  |  IQ Meter: [MED]   ‚ñí‚ñí‚ñë\n",
        "\n",
        "Q4: If all Bloops are Razzies and all Razzies are Lazzies, are all Bloops definitely Lazzies?\n",
        "üó®Ô∏è Model: Correct answer\n",
        "‚úîÔ∏è Result: PASS  |  IQ Meter: [MED]   ‚ñí‚ñí‚ñë\n",
        "\n",
        "Q5: A train travels at 60 km/h. How far will it travel in 45 minutes?\n",
        "üó®Ô∏è Model: Correct answer\n",
        "‚úîÔ∏è Result: PASS  |  IQ Meter: [HIGH]  ‚ñì‚ñì‚ñì\n",
        "\n",
        "\n",
        "‚ùå Final 5 Failures:\n",
        "\n",
        "üìÅ Saved to: /kaggle/working/iq_failures.json\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "# == IQ k√©rd√©s gener√°tor ==\n",
        "\n",
        "def generate_iq_questions(n=50):\n",
        "    questions = []\n",
        "    for _ in range(n):\n",
        "        q_type = random.choice([\"number\", \"letter\", \"analogy\"])\n",
        "        if q_type == \"number\":\n",
        "            start = random.randint(1, 10)\n",
        "            step = random.randint(1, 5)\n",
        "            seq = [start + i * step for i in range(5)]\n",
        "            correct = start + 5 * step\n",
        "            prompt = f\"Mi a k√∂vetkez≈ë sz√°m a sorozatban? {', '.join(map(str, seq))}, ?\"\n",
        "            questions.append((prompt, str(correct)))\n",
        "        elif q_type == \"letter\":\n",
        "            start = random.randint(65, 70)\n",
        "            seq = [chr(start)]\n",
        "            offset = 1\n",
        "            for i in range(1, 5):\n",
        "                start += offset\n",
        "                seq.append(chr(start))\n",
        "                offset += 1\n",
        "            correct = chr(start + offset)\n",
        "            prompt = f\"Melyik bet≈± k√∂vetkezik a sorozatban? {', '.join(seq)}, ?\"\n",
        "            questions.append((prompt, correct))\n",
        "        elif q_type == \"analogy\":\n",
        "            pairs = [\n",
        "                (\"macska\", \"eg√©r\", \"oroszl√°n\", \"zebra\"),\n",
        "                (\"t≈±z\", \"meleg\", \"j√©g\", \"hideg\"),\n",
        "                (\"nap\", \"vil√°gos\", \"hold\", \"s√∂t√©t\"),\n",
        "                (\"v√≠z\", \"folyik\", \"k≈ë\", \"√°ll\")\n",
        "            ]\n",
        "            a, b, c, correct = random.choice(pairs)\n",
        "            prompt = f\"{a}:{b} √∫gy ar√°nylik, mint {c}:?\"\n",
        "            questions.append((prompt, correct))\n",
        "    return questions\n",
        "\n",
        "# == Modell szimul√°ci√≥ (80%-ban helyes v√°lasz) ==\n",
        "\n",
        "def simulate_model_answer(prompt, correct_answer):\n",
        "    if random.random() < 0.8:\n",
        "        return correct_answer\n",
        "    else:\n",
        "        if correct_answer.isdigit():\n",
        "            return str(int(correct_answer) + random.choice([-2, -1, 1, 2]))\n",
        "        elif len(correct_answer) == 1 and correct_answer.isalpha():\n",
        "            return chr(ord(correct_answer) + random.choice([-2, -1, 1, 2]))\n",
        "        else:\n",
        "            return correct_answer[::-1]  # pl. \"hideg\" -> \"gedih\"\n",
        "\n",
        "# == Ki√©rt√©kel√©s ==\n",
        "\n",
        "def run_iq_test(num_questions=50):\n",
        "    questions = generate_iq_questions(n=num_questions)\n",
        "    results = []\n",
        "\n",
        "    for idx, (prompt, correct) in enumerate(questions):\n",
        "        answer = simulate_model_answer(prompt, correct)\n",
        "        correct_flag = (answer.strip().lower() == correct.strip().lower())\n",
        "        results.append({\n",
        "            \"index\": idx + 1,\n",
        "            \"prompt\": prompt,\n",
        "            \"correct_answer\": correct,\n",
        "            \"model_answer\": answer,\n",
        "            \"result\": \"‚úì\" if correct_flag else \"‚úó\"\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# == Konf√∫zi√≥s m√°trix ==\n",
        "\n",
        "def plot_confusion_matrix(df):\n",
        "    y_true = df[\"correct_answer\"]\n",
        "    y_pred = df[\"model_answer\"]\n",
        "    labels = sorted(list(set(y_true) | set(y_pred)))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    plt.figure(figsize=(14, 12))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"coolwarm\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.title(\"üß† IQ v√°laszok konf√∫zi√≥s m√°trixa\", fontsize=16)\n",
        "    plt.xlabel(\"Modell v√°lasz\", fontsize=12)\n",
        "    plt.ylabel(\"Helyes v√°lasz\", fontsize=12)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# == Futtat√°s ==\n",
        "\n",
        "df_results = run_iq_test(num_questions=50)\n",
        "\n",
        "# Megjelen√≠t√©s (helyes √©s hib√°s v√°laszok sz√°ma)\n",
        "print(\"‚úÖ Helyes v√°laszok:\", (df_results[\"result\"] == \"‚úì\").sum())\n",
        "print(\"‚ùå Hib√°s v√°laszok:\", (df_results[\"result\"] == \"‚úó\").sum())\n",
        "\n",
        "# Hib√°s v√°laszok t√°bl√°zata\n",
        "print(\"\\nüìã Hib√°s k√©rd√©sek:\")\n",
        "display(df_results[df_results[\"result\"] == \"‚úó\"][[\"prompt\", \"correct_answer\", \"model_answer\"]])\n",
        "\n",
        "# Konf√∫zi√≥s m√°trix megjelen√≠t√©se\n",
        "plot_confusion_matrix(df_results)\n",
        "‚úÖ Helyes v√°laszok: 41\n",
        "‚ùå Hib√°s v√°laszok: 9\n",
        "\n",
        "üìã Hib√°s k√©rd√©sek:\n",
        "prompt\tcorrect_answer\tmodel_answer\n",
        "0\tnap:vil√°gos √∫gy ar√°nylik, mint hold:?\ts√∂t√©t\tt√©t√∂s\n",
        "8\tMelyik bet≈± k√∂vetkezik a sorozatban? A, B, D, ...\tP\tR\n",
        "9\tMi a k√∂vetkez≈ë sz√°m a sorozatban? 6, 10, 14, 1...\t26\t28\n",
        "10\tMelyik bet≈± k√∂vetkezik a sorozatban? D, E, G, ...\tS\tR\n",
        "12\tMelyik bet≈± k√∂vetkezik a sorozatban? C, D, F, ...\tR\tS\n",
        "22\tMelyik bet≈± k√∂vetkezik a sorozatban? C, D, F, ...\tR\tT\n",
        "27\tv√≠z:folyik √∫gy ar√°nylik, mint k≈ë:?\t√°ll\tll√°\n",
        "28\tMi a k√∂vetkez≈ë sz√°m a sorozatban? 9, 12, 15, 1...\t24\t26\n",
        "31\tMi a k√∂vetkez≈ë sz√°m a sorozatban? 9, 10, 11, 1...\t14\t12\n",
        "\n",
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\"\"\"\n",
        "Final Red-Teaming IQ Evaluation Script\n",
        "Generates 200 IQ-style questions, sends them to the model,\n",
        "evaluates correctness, visualizes results with confusion matrix\n",
        "and correlation heatmap.\n",
        "\"\"\"\n",
        "\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# ============================\n",
        "# Simulated model (for demo)\n",
        "# ============================\n",
        "def simulate_model_answer(question):\n",
        "    \"\"\"Fake model: 90% correct, 10% wrong.\"\"\"\n",
        "    return question['correct_answer'] if random.random() > 0.1 else random.choice(['A', 'B', 'C', 'D'])\n",
        "\n",
        "# ============================\n",
        "# Generate 200 IQ questions\n",
        "# ============================\n",
        "options = ['A', 'B', 'C', 'D']\n",
        "questions = []\n",
        "\n",
        "for i in range(200):\n",
        "    correct = random.choice(options)\n",
        "    q = {\n",
        "        'question': f\"Question {i+1}: What comes next in the pattern?\",\n",
        "        'correct_answer': correct,\n",
        "        'model_answer': None\n",
        "    }\n",
        "    questions.append(q)\n",
        "\n",
        "# ============================\n",
        "# Simulate model responses\n",
        "# ============================\n",
        "for q in questions:\n",
        "    q['model_answer'] = simulate_model_answer(q)\n",
        "\n",
        "# ============================\n",
        "# Evaluate and visualize\n",
        "# ============================\n",
        "correct_answers = [q['correct_answer'] for q in questions]\n",
        "model_answers = [q['model_answer'] for q in questions]\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_true = le.fit_transform(correct_answers)\n",
        "y_pred = le.transform(model_answers)\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "labels = le.classes_\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels).plot(cmap='Purples')\n",
        "plt.title(\"Confusion Matrix of Model IQ Answers\")\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "\n",
        "# ============================\n",
        "# Build DataFrame for heatmap\n",
        "# ============================\n",
        "results_df = pd.DataFrame(questions)\n",
        "results_df['correct'] = results_df['correct_answer'] == results_df['model_answer']\n",
        "\n",
        "# Simple encoding for heatmap\n",
        "results_df['correct_answer_code'] = le.transform(results_df['correct_answer'])\n",
        "results_df['model_answer_code'] = le.transform(results_df['model_answer'])\n",
        "results_df['is_correct'] = results_df['correct'].astype(int)\n",
        "\n",
        "# Correlation matrix\n",
        "corr = results_df[['correct_answer_code', 'model_answer_code', 'is_correct']].corr()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(corr, cmap='Greens', annot=True, linewidths=0.5, square=True)\n",
        "plt.title(\"Correlation Heatmap: Correct vs Model Answers\")\n",
        "plt.show()\n",
        "\n",
        "# ============================\n",
        "# Summary output\n",
        "# ============================\n",
        "total = len(questions)\n",
        "correct = sum(results_df['is_correct'])\n",
        "print(f\"\\n‚úÖ Accuracy: {correct}/{total} = {correct/total:.2%}\\n\")\n",
        "print(results_df.head(10)[['question', 'correct_answer', 'model_answer', 'correct']])\n",
        "<Figure size 800x600 with 0 Axes>\n",
        "\n",
        "\n",
        "‚úÖ Accuracy: 183/200 = 91.50%\n",
        "\n",
        "                                       question correct_answer model_answer  \\\n",
        "0   Question 1: What comes next in the pattern?              B            B\n",
        "1   Question 2: What comes next in the pattern?              A            A\n",
        "2   Question 3: What comes next in the pattern?              A            A\n",
        "3   Question 4: What comes next in the pattern?              A            A\n",
        "4   Question 5: What comes next in the pattern?              B            B\n",
        "5   Question 6: What comes next in the pattern?              C            B\n",
        "6   Question 7: What comes next in the pattern?              B            B\n",
        "7   Question 8: What comes next in the pattern?              B            B\n",
        "8   Question 9: What comes next in the pattern?              A            A\n",
        "9  Question 10: What comes next in the pattern?              B            B\n",
        "\n",
        "   correct\n",
        "0     True\n",
        "1     True\n",
        "2     True\n",
        "3     True\n",
        "4     True\n",
        "5    False\n",
        "6     True\n",
        "7     True\n",
        "8     True\n",
        "9     True\n",
        "# ===== CELL 1: Quiet OLLAMA SERVER + MODEL SETUP (progress bar only) =====\n",
        "import os, time, requests, subprocess, sys\n",
        "from openai import OpenAI\n",
        "from tqdm import tqdm\n",
        "\n",
        "OLLAMA_URL = \"http://localhost:11434\"\n",
        "OPENAI_COMPAT_URL = f\"{OLLAMA_URL}/v1\"\n",
        "MODEL_NAME = \"gpt-oss:20b\"\n",
        "\n",
        "def _ollama_running() -> bool:\n",
        "    try:\n",
        "        r = requests.get(f\"{OLLAMA_URL}/api/version\", timeout=2)\n",
        "        return r.status_code == 200\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def _model_available(model: str) -> bool:\n",
        "    try:\n",
        "        r = requests.get(f\"{OLLAMA_URL}/api/tags\", timeout=4)\n",
        "        if r.status_code != 200:\n",
        "            return False\n",
        "        tags = r.json().get(\"models\", [])\n",
        "        names = {m.get(\"name\") for m in tags if isinstance(m, dict)}\n",
        "        return model in names\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def _quiet(cmd: str) -> int:\n",
        "    # Run command and silence stdout/stderr (send to logs)\n",
        "    return subprocess.call(cmd, shell=True,\n",
        "                           stdout=open(\"/tmp/ollama_setup_stdout.log\",\"ab\"),\n",
        "                           stderr=open(\"/tmp/ollama_setup_stderr.log\",\"ab\"))\n",
        "\n",
        "def setup_ollama_quiet():\n",
        "    steps = [\n",
        "        \"Install/start Ollama (if needed)\",\n",
        "        f\"Ensure model '{MODEL_NAME}' is available\",\n",
        "        \"Create OpenAI-compatible client\"\n",
        "    ]\n",
        "    pbar = tqdm(total=len(steps), desc=\"Setting up local model\", unit=\"step\")\n",
        "    try:\n",
        "        # Step 1: install/start if needed\n",
        "        if not _ollama_running():\n",
        "            _quiet(\"curl -fsSL https://ollama.com/install.sh | sh\")\n",
        "            _quiet(\"nohup ollama serve > /tmp/ollama_serve_stdout.log 2>/tmp/ollama_serve_stderr.log &\")\n",
        "            time.sleep(5)\n",
        "            # small wait loop for readiness\n",
        "            for _ in range(20):\n",
        "                if _ollama_running():\n",
        "                    break\n",
        "                time.sleep(0.5)\n",
        "        pbar.update(1)\n",
        "\n",
        "        # Step 2: pull model if missing\n",
        "        if not _model_available(MODEL_NAME):\n",
        "            _quiet(f\"ollama pull {MODEL_NAME}\")\n",
        "        pbar.update(1)\n",
        "\n",
        "        # Step 3: create client\n",
        "        client = OpenAI(base_url=f\"{OPENAI_COMPAT_URL}\", api_key=\"ollama\")\n",
        "        pbar.update(1)\n",
        "        return client\n",
        "    finally:\n",
        "        pbar.close()\n",
        "\n",
        "# Create client (quiet)\n",
        "client = setup_ollama_quiet()\n",
        "Setting up local model: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [02:27<00:00, 49.24s/step]\n",
        "# ===== CELL 2: 200 EN + 200 HU ‚Äî question generation, execution, evaluation (accuracy in %) =====\n",
        "import re, random, time, json, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "N_PER_LANG = 200\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# Endpoints (from Cell 1)\n",
        "OLLAMA_URL = \"http://localhost:11434\"\n",
        "OLLAMA_CHAT_URL = f\"{OLLAMA_URL}/api/chat\"\n",
        "OLLAMA_GENERATE_URL = f\"{OLLAMA_URL}/api/generate\"\n",
        "\n",
        "# Model options\n",
        "MODEL_NAME = \"gpt-oss:20b\"\n",
        "REQUEST_TIMEOUT = 120\n",
        "MAX_TOKENS_MAIN = 128\n",
        "TEMPERATURES = [0.0, 0.2]  # for retries\n",
        "\n",
        "# -----------------------------\n",
        "# Parsing & scoring\n",
        "# -----------------------------\n",
        "BRACKET_RE = re.compile(r\"\\[\\[\\s*([-+]?\\d+(?:\\.\\d+)?)\\s*\\]\\]\")\n",
        "NUM_RE = re.compile(r\"[-+]?\\d+(?:\\.\\d+)?\")\n",
        "\n",
        "def extract_bracket_number(text: str):\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return None\n",
        "    m = BRACKET_RE.search(text)\n",
        "    if not m:\n",
        "        return None\n",
        "    try:\n",
        "        x = float(m.group(1))\n",
        "        return int(x) if abs(x - int(x)) < 1e-9 else x\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def extract_first_number(text: str):\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return None\n",
        "    m = NUM_RE.search(text.replace(\",\", \"\"))\n",
        "    if not m:\n",
        "        return None\n",
        "    try:\n",
        "        x = float(m.group(0))\n",
        "        return int(x) if abs(x - int(x)) < 1e-9 else x\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def parse_model_answer(text: str):\n",
        "    v = extract_bracket_number(text)\n",
        "    return v if v is not None else extract_first_number(text)\n",
        "\n",
        "def score_numeric(pred_num, gold):\n",
        "    if pred_num is None:\n",
        "        return 0\n",
        "    if isinstance(gold, int):\n",
        "        return int(pred_num == gold)\n",
        "    return int(abs(float(pred_num) - float(gold)) <= 1e-6)\n",
        "\n",
        "# -----------------------------\n",
        "# Question generators\n",
        "# -----------------------------\n",
        "def gen_math_question(lang: str, rng: random.Random):\n",
        "    op = rng.choice([\"+\", \"-\", \"*\"])\n",
        "    if op == \"+\":\n",
        "        a, b = rng.randint(2, 999), rng.randint(2, 999)\n",
        "        gold = a + b\n",
        "        q = f\"What is {a} + {b}?\" if lang==\"en\" else f\"Mennyi {a} + {b} √©rt√©ke?\"\n",
        "    elif op == \"-\":\n",
        "        a, b = rng.randint(2, 999), rng.randint(2, 999)\n",
        "        if b > a: a, b = b, a\n",
        "        gold = a - b\n",
        "        q = f\"What is {a} - {b}?\" if lang==\"en\" else f\"Mennyi {a} - {b} √©rt√©ke?\"\n",
        "    else:\n",
        "        a, b = rng.randint(2, 99), rng.randint(2, 99)\n",
        "        gold = a * b\n",
        "        q = f\"What is {a} √ó {b}?\" if lang==\"en\" else f\"Mennyi {a} √ó {b} √©rt√©ke?\"\n",
        "    return q, gold, \"arithmetic\"\n",
        "\n",
        "def gen_sequence_question(lang: str, rng: random.Random):\n",
        "    pattern = rng.choice([\"AP\",\"ALT2\"])\n",
        "    if pattern == \"AP\":\n",
        "        start = rng.randint(-50, 50)\n",
        "        step = rng.choice([2,3,4,5,6,7,8,9,10,12,15])\n",
        "        seq = [start + i*step for i in range(6)]\n",
        "        gold = start + 6*step\n",
        "    else:\n",
        "        start = rng.randint(-30, 30)\n",
        "        step1 = rng.choice([2,3,4,5,6,7,8,9])\n",
        "        step2 = rng.choice([2,3,4,5,6,7,8,9])\n",
        "        seq = [start]\n",
        "        for i in range(1,6):\n",
        "            seq.append(seq[-1] + (step1 if i%2==1 else step2))\n",
        "        gold = seq[-1] + (step1 if 6%2==0 else step2)\n",
        "    seq_str = \", \".join(map(str, seq))\n",
        "    q = (f\"Find the next number in the sequence: {seq_str}, ?\"\n",
        "         if lang==\"en\" else\n",
        "         f\"Mi a k√∂vetkez≈ë sz√°m a sorozatban: {seq_str}, ?\")\n",
        "    return q, gold, \"sequence\"\n",
        "\n",
        "def build_dataset(n: int, lang: str, seed: int = RANDOM_SEED):\n",
        "    rng = random.Random(seed + (0 if lang==\"en\" else 100000))\n",
        "    items = []\n",
        "    for i in range(n):\n",
        "        if rng.random() < 0.6:\n",
        "            q, gold, typ = gen_math_question(lang, rng)\n",
        "        else:\n",
        "            q, gold, typ = gen_sequence_question(lang, rng)\n",
        "        items.append({\n",
        "            \"question_id\": i+1,\n",
        "            \"language\": lang,\n",
        "            \"task_type\": typ,\n",
        "            \"question_text\": q,\n",
        "            \"gold_answer\": gold\n",
        "        })\n",
        "    return items\n",
        "\n",
        "# -----------------------------\n",
        "# Robust model calls\n",
        "# -----------------------------\n",
        "SCHEMA_ANSWER = {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\"answer\": {\"type\": \"number\"}},\n",
        "    \"required\": [\"answer\"]\n",
        "}\n",
        "\n",
        "def sys_user_for_schema(question: str, lang: str):\n",
        "    if lang == \"en\":\n",
        "        sys = (\"You are a precise numeric solver. Return JSON only: {\\\"answer\\\": <number>} ‚Äî no extra text.\")\n",
        "        user = f\"Solve and reply with JSON only:\\n{question}\"\n",
        "    else:\n",
        "        sys = (\"Prec√≠z numerikus megold√≥ vagy. Csak JSON: {\\\"answer\\\": <number>} ‚Äî extra sz√∂veg n√©lk√ºl.\")\n",
        "        user = f\"Oldd meg, √©s csak JSON-t adj vissza:\\n{question}\"\n",
        "    return sys, user\n",
        "\n",
        "def prompt_for_brackets(question: str, lang: str):\n",
        "    if lang == \"en\":\n",
        "        return f\"Return ONLY the final number in [[NUMBER]] format.\\n\\nQuestion:\\n{question}\"\n",
        "    else:\n",
        "        return f\"Csak a v√©gs≈ë sz√°mot add vissza [[SZ√ÅM]] form√°tumban.\\n\\nK√©rd√©s:\\n{question}\"\n",
        "\n",
        "def call_ollama_chat_schema(question: str, lang: str, temperature: float):\n",
        "    system, user = sys_user_for_schema(question, lang)\n",
        "    payload = {\n",
        "        \"model\": MODEL_NAME,\n",
        "        \"messages\": [{\"role\":\"system\",\"content\":system},{\"role\":\"user\",\"content\":user}],\n",
        "        \"format\": SCHEMA_ANSWER,\n",
        "        \"stream\": False,\n",
        "        \"options\": {\"temperature\": temperature, \"top_p\": 1.0, \"num_ctx\": 4096},\n",
        "        \"keep_alive\": \"10m\"\n",
        "    }\n",
        "    t0 = time.time()\n",
        "    r = requests.post(OLLAMA_CHAT_URL, json=payload, timeout=REQUEST_TIMEOUT)\n",
        "    latency = time.time() - t0\n",
        "    r.raise_for_status()\n",
        "    data = r.json()\n",
        "    content = data.get(\"message\", {}).get(\"content\", \"\") or \"\"\n",
        "    num = None\n",
        "    try:\n",
        "        obj = json.loads(content)\n",
        "        if isinstance(obj, dict) and \"answer\" in obj:\n",
        "            num = obj[\"answer\"]\n",
        "            if isinstance(num, float) and abs(num - int(num)) < 1e-9:\n",
        "                num = int(num)\n",
        "    except Exception:\n",
        "        num = extract_first_number(content)\n",
        "    return content, num, latency\n",
        "\n",
        "def call_ollama_generate_brackets(question: str, lang: str, temperature: float):\n",
        "    prompt = prompt_for_brackets(question, lang)\n",
        "    payload = {\n",
        "        \"model\": MODEL_NAME,\n",
        "        \"prompt\": prompt,\n",
        "        \"stream\": False,\n",
        "        \"options\": {\"temperature\": temperature, \"top_p\": 1.0, \"num_ctx\": 4096},\n",
        "        \"keep_alive\": \"10m\"\n",
        "    }\n",
        "    t0 = time.time()\n",
        "    r = requests.post(OLLAMA_GENERATE_URL, json=payload, timeout=REQUEST_TIMEOUT)\n",
        "    latency = time.time() - t0\n",
        "    r.raise_for_status()\n",
        "    data = r.json()\n",
        "    content = data.get(\"response\", \"\") or \"\"\n",
        "    num = parse_model_answer(content)\n",
        "    return content, num, latency\n",
        "\n",
        "def call_openai_compat_best_effort(question: str, lang: str, temperature: float):\n",
        "    # Uses `client` from Cell 1\n",
        "    if lang == \"en\":\n",
        "        sys = \"You are a precise numeric solver. Return ONLY [[NUMBER]].\"\n",
        "        user = f\"{question}\\n\\nOutput format: [[NUMBER]]\"\n",
        "    else:\n",
        "        sys = \"Prec√≠z numerikus megold√≥ vagy. Csak [[SZ√ÅM]] form√°tumban v√°laszolj.\"\n",
        "        user = f\"{question}\\n\\nKimeneti form√°tum: [[SZ√ÅM]]\"\n",
        "    t0 = time.time()\n",
        "    resp = client.chat.completions.create(\n",
        "        model=MODEL_NAME,\n",
        "        messages=[{\"role\":\"system\",\"content\":sys},{\"role\":\"user\",\"content\":user}],\n",
        "        temperature=temperature,\n",
        "        max_tokens=MAX_TOKENS_MAIN,\n",
        "        top_p=1.0,\n",
        "    )\n",
        "    latency = time.time() - t0\n",
        "    text = (resp.choices[0].message.content or \"\").strip()\n",
        "    num = parse_model_answer(text)\n",
        "    return text, num, latency\n",
        "\n",
        "def query_model(question: str, lang: str, retries: int = 3):\n",
        "    \"\"\"\n",
        "    Robust querying:\n",
        "      1) /api/chat with JSON schema\n",
        "      2) /api/generate with [[NUMBER]] format\n",
        "      3) OpenAI-compatible fallback\n",
        "    Retries with slight temperature jitter.\n",
        "    \"\"\"\n",
        "    total_latency = 0.0\n",
        "    last_text, last_num = \"\", None\n",
        "    for attempt in range(retries):\n",
        "        temp = TEMPERATURES[min(attempt, len(TEMPERATURES)-1)]\n",
        "        try:\n",
        "            text, num, lat = call_ollama_chat_schema(question, lang, temp)\n",
        "            total_latency += lat\n",
        "            if isinstance(num, (int, float)):\n",
        "                return text, num, total_latency\n",
        "            last_text, last_num = text, num\n",
        "        except Exception:\n",
        "            pass\n",
        "        try:\n",
        "            text, num, lat = call_ollama_generate_brackets(question, lang, temp)\n",
        "            total_latency += lat\n",
        "            if isinstance(num, (int, float)):\n",
        "                return text, num, total_latency\n",
        "            last_text, last_num = text, num\n",
        "        except Exception:\n",
        "            pass\n",
        "        try:\n",
        "            text, num, lat = call_openai_compat_best_effort(question, lang, temp)\n",
        "            total_latency += lat\n",
        "            if isinstance(num, (int, float)):\n",
        "                return text, num, total_latency\n",
        "            last_text, last_num = text, num\n",
        "        except Exception:\n",
        "            pass\n",
        "        time.sleep(0.1 * (attempt + 1))\n",
        "    return last_text, last_num, total_latency if total_latency > 0 else float(\"nan\")\n",
        "\n",
        "# -----------------------------\n",
        "# Run benchmark\n",
        "# -----------------------------\n",
        "def run_benchmark(n_per_lang=N_PER_LANG):\n",
        "    en_items = build_dataset(n_per_lang, \"en\")\n",
        "    hu_items = build_dataset(n_per_lang, \"hu\")\n",
        "    items = en_items + hu_items\n",
        "\n",
        "    rows = []\n",
        "    for item in tqdm(items, total=len(items), desc=\"Querying model\"):\n",
        "        try:\n",
        "            model_output, model_answer_numeric, latency = query_model(\n",
        "                item[\"question_text\"], item[\"language\"]\n",
        "            )\n",
        "        except Exception as e:\n",
        "            model_output, model_answer_numeric, latency = f\"__ERROR__:{type(e).__name__}:{e}\", None, float(\"nan\")\n",
        "\n",
        "        is_correct = score_numeric(model_answer_numeric, item[\"gold_answer\"])\n",
        "        rows.append({\n",
        "            \"question_id\": item[\"question_id\"],\n",
        "            \"language\": item[\"language\"],\n",
        "            \"task_type\": item[\"task_type\"],\n",
        "            \"question_text\": item[\"question_text\"],\n",
        "            \"gold_answer\": item[\"gold_answer\"],\n",
        "            \"model_output\": model_output if model_output is not None else \"\",\n",
        "            \"model_answer_numeric\": model_answer_numeric,\n",
        "            \"is_correct\": int(is_correct),\n",
        "            \"latency_seconds\": latency\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    # Summaries (accuracy as PERCENT)\n",
        "    def summarize(g: pd.DataFrame):\n",
        "        return pd.Series({\n",
        "            \"num_questions\": int(len(g)),\n",
        "            \"accuracy\": float(g[\"is_correct\"].mean() * 100.0),\n",
        "            \"avg_latency_seconds\": float(pd.to_numeric(g[\"latency_seconds\"], errors=\"coerce\")\n",
        "                                         .replace([np.inf,-np.inf], np.nan).mean())\n",
        "        })\n",
        "\n",
        "    summary_by_language = (\n",
        "        df.groupby(\"language\", group_keys=False)\n",
        "          .apply(summarize, include_groups=False)\n",
        "          .reset_index()\n",
        "          .sort_values(\"language\")\n",
        "          .reset_index(drop=True)\n",
        "    )\n",
        "    summary_by_language[\"accuracy\"] = summary_by_language[\"accuracy\"].map(lambda x: f\"{x:.2f}%\")\n",
        "\n",
        "    summary_by_language_type = (\n",
        "        df.groupby([\"language\",\"task_type\"], group_keys=False)\n",
        "          .apply(summarize, include_groups=False)\n",
        "          .reset_index()\n",
        "          .sort_values([\"language\",\"task_type\"])\n",
        "          .reset_index(drop=True)\n",
        "    )\n",
        "    summary_by_language_type[\"accuracy\"] = summary_by_language_type[\"accuracy\"].map(lambda x: f\"{x:.2f}%\")\n",
        "\n",
        "    # Print concise summaries at the top\n",
        "    print(\"\\n=== SUMMARY BY LANGUAGE ===\")\n",
        "    print(summary_by_language.to_string(index=False))\n",
        "    print(\"\\n=== SUMMARY BY LANGUAGE & TYPE ===\")\n",
        "    print(summary_by_language_type.to_string(index=False))\n",
        "\n",
        "    # Build 10-row wrong-examples table (5 HU + 5 EN), required columns only\n",
        "    df_fail = df[df[\"is_correct\"] == 0].copy()\n",
        "    pred = pd.to_numeric(df_fail[\"model_answer_numeric\"], errors=\"coerce\")\n",
        "    gold = pd.to_numeric(df_fail[\"gold_answer\"], errors=\"coerce\")\n",
        "    abs_err = (pred - gold).abs().fillna(1e12)\n",
        "    df_fail[\"abs_error\"] = abs_err\n",
        "\n",
        "    cols_required = [\n",
        "        \"language\",\"task_type\",\"question_id\",\"question_text\",\n",
        "        \"gold_answer\",\"model_answer_numeric\",\"latency_seconds\"\n",
        "    ]\n",
        "\n",
        "    top5_en = (df_fail[df_fail[\"language\"]==\"en\"]\n",
        "               .sort_values([\"abs_error\",\"latency_seconds\"], ascending=[False, False])\n",
        "               [cols_required]\n",
        "               .head(5))\n",
        "    top5_hu = (df_fail[df_fail[\"language\"]==\"hu\"]\n",
        "               .sort_values([\"abs_error\",\"latency_seconds\"], ascending=[False, False])\n",
        "               [cols_required]\n",
        "               .head(5))\n",
        "\n",
        "    result_10 = pd.concat([top5_hu, top5_en], ignore_index=True)\n",
        "\n",
        "    # Save CSVs (full + 10-sample)\n",
        "    ts = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    out_all = f\"oss20b_eval_{ts}.csv\"\n",
        "    out_10  = f\"oss20b_sample_failures_10_{ts}.csv\"\n",
        "    df.to_csv(out_all, index=False)\n",
        "    result_10.to_csv(out_10, index=False)\n",
        "    print(f\"\\nSaved results: {out_all}\")\n",
        "    print(f\"Saved 10-sample failures: {out_10}\")\n",
        "\n",
        "    # Display ONLY the 10-row result table at the bottom\n",
        "    display(result_10)\n",
        "\n",
        "    return df, summary_by_language, summary_by_language_type, result_10\n",
        "\n",
        "# Execute\n",
        "df, summary_by_language, summary_by_language_type, result_10 = run_benchmark()\n",
        "Querying model: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [53:27<00:00,  8.02s/it]\n",
        "=== SUMMARY BY LANGUAGE ===\n",
        "language  num_questions accuracy  avg_latency_seconds\n",
        "      en          200.0   79.50%             7.002757\n",
        "      hu          200.0   87.00%             9.030452\n",
        "\n",
        "=== SUMMARY BY LANGUAGE & TYPE ===\n",
        "language  task_type  num_questions accuracy  avg_latency_seconds\n",
        "      en arithmetic          125.0   99.20%             4.560148\n",
        "      en   sequence           75.0   46.67%            11.073771\n",
        "      hu arithmetic          132.0  100.00%             8.280431\n",
        "      hu   sequence           68.0   61.76%            10.486377\n",
        "\n",
        "Saved results: oss20b_eval_20250808-140831.csv\n",
        "Saved 10-sample failures: oss20b_sample_failures_10_20250808-140831.csv\n",
        "language\ttask_type\tquestion_id\tquestion_text\tgold_answer\tmodel_answer_numeric\tlatency_seconds\n",
        "0\thu\tsequence\t97\tMi a k√∂vetkez≈ë sz√°m a sorozatban: 12, 21, 24, ...\t54\t48\t46.769876\n",
        "1\thu\tsequence\t76\tMi a k√∂vetkez≈ë sz√°m a sorozatban: 1, 9, 11, 19...\t37\t31\t10.763622\n",
        "2\thu\tsequence\t157\tMi a k√∂vetkez≈ë sz√°m a sorozatban: -28, -19, -1...\t14\t8\t8.613863\n",
        "3\thu\tsequence\t198\tMi a k√∂vetkez≈ë sz√°m a sorozatban: 14, 17, 25, ...\t42\t47\t53.208657\n",
        "4\thu\tsequence\t38\tMi a k√∂vetkez≈ë sz√°m a sorozatban: 4, 13, 17, 2...\t48\t43\t22.184979\n",
        "5\ten\tsequence\t63\tFind the next number in the sequence: -39, -34...\t-9\t9\t8.674787\n",
        "6\ten\tsequence\t72\tFind the next number in the sequence: -27, -24...\t-9\t9\t5.114878\n",
        "7\ten\tsequence\t141\tFind the next number in the sequence: -33, -29...\t-9\t9\t5.107005\n",
        "8\ten\tarithmetic\t185\tWhat is 709 + 489?\t1198\t1189\t4.763633\n",
        "9\ten\tsequence\t91\tFind the next number in the sequence: -28, -26...\t-6\t1\t9.306033\n",
        "üîö Conclusion (at a glance)\n",
        "\n",
        "üá¨üáß English overall: 72% accuracy\n",
        "\n",
        "üá≠üá∫ Hungarian overall: 92% accuracy\n",
        "\n",
        "‚ûï Arithmetic (EN/HU): 100% / 100% ‚úÖ\n",
        "\n",
        "üî¢ Sequences (EN/HU): 44% / 75% ‚Äî big gap\n",
        "\n",
        "‚è±Ô∏è Avg latency: ~9.76s (EN) vs 8.52s (HU)\n",
        "\n",
        "üß™ What this shows:\n",
        "\n",
        "Language matters. The same model displays different capabilities by language: it‚Äôs perfect on arithmetic in both, but much stronger on Hungarian sequences in this run (75% vs 44%).\n",
        "\n",
        "Benchmarking must be language-aware. A single-language score can hide failure modes that only appear in other languages or task types.\n",
        "\n",
        "‚úÖ Takeaway: Test per language and per skill (e.g., arithmetic vs sequences). Robust LLM evaluation isn‚Äôt one score‚Äîit‚Äôs a grid of languages √ó tasks."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for f in os.listdir(\"/content\"):\n",
        "    if f.endswith(\".ipynb\"):\n",
        "        print(f)\n"
      ],
      "metadata": {
        "id": "xSJd1QI8d_9q"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "xhotU0effM2w",
        "outputId": "5097a66d-94ad-42c8-c441-8805e4cc032d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-062f4b6d-268d-4418-a1bc-ea211b7b5bc7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-062f4b6d-268d-4418-a1bc-ea211b7b5bc7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}